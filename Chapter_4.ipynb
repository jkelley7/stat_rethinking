{"cells":[{"source":["import numpy as np\n","import pandas as pd\n","from scipy import stats\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import arviz as az\n","from collections import Counter\n","from scipy.interpolate import griddata\n","import pymc3 as pm\n","import theano as tt\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.1a"],"metadata":{}},{"source":["np.random.seed(42)\n","for i in range(1,18,4):\n","    pos = np.sum(np.random.uniform(low = -1, high = 1,size = (i,1000)), axis= 0)\n","    sns.distplot(pos)\n","    plt.xlabel('position')\n","    plt.ylabel('Density')\n","    plt.title(f'{i} steps')\n","    plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.2 & 4.3\n","\n"," small deviates multipled together form a normal distribution. This is due to multiplying small numbers together are approximately the same as addition"],"metadata":{}},{"source":["np.random.seed(42)\n","growth = np.prod(1 + np.random.uniform(0,.1, size = (12,10000)), axis = 0)\n","sns.distplot(growth,norm_hist=True)\n","plt.xlabel('product')\n","plt.ylabel('Density')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.4"],"metadata":{}},{"source":["big = np.prod(1 + np.random.uniform(0,.5, size = (12,10000)), axis = 0)\n","small = np.prod(1 + np.random.uniform(0,.01, size = (12,10000)), axis = 0)\n","plt.figure()\n","sns.distplot(big,norm_hist=False)\n","plt.xlabel('product')\n","plt.ylabel('Density')\n","plt.title('big')\n","plt.figure()\n","sns.distplot(small,norm_hist=False)\n","plt.xlabel('product')\n","plt.ylabel('Density')\n","plt.title('small')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.5\n","\n"," Large deviates which are multipled together tend to produce gaussians on the log scale\n"," Why? because adding logs is equivalent to multiplying original numbers"],"metadata":{}},{"source":["np.random.seed(42)\n","log_big = np.log(np.prod(1 + np.random.uniform(0,.5, size = (12,10000)), axis = 0))\n","sns.distplot(log_big,norm_hist=False)\n","plt.xlabel('product')\n","plt.ylabel('Density')\n","plt.title('log big')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.6"],"metadata":{}},{"source":["w = 6\n","n = 9\n","p_grid = np.linspace(0,1,100)\n","posterior = stats.binom.pmf(k = w,n = n, p= p_grid)*stats.uniform.pdf(p_grid, 0 ,1) #likelihood * prior\n","posterior = posterior/np.sum(posterior)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["plt.plot(p_grid, posterior)\n","plt.xlabel('probability')\n","plt.ylabel('density')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.7 - 4.10"],"metadata":{}},{"source":["# 4.7\n","d = pd.read_csv('.\\data\\Howell1.csv', sep = \";\")\n","d.head()\n","\n","# 4.8\n","print(d.info())\n","\n","# 4.9\n","d['height'].head()\n","\n","#4.10\n","d2 = d.query('age >= 18')\n","print(f'the length of d2 is {len(d2)}')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# plot the height of people over the age of 18\n","# it looks rather gaussian in shape. This maybe because height is the sum of man small growth factors\n","# as we said previously, distribution of sums tends to converge to gaussian dist\n","sns.distplot(d2['height'])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.11"],"metadata":{}},{"source":["mu = np.linspace(100,250, 150)\n","plt.plot(mu, stats.norm.pdf(mu, 178, 20))\n","plt.xlabel('heights (cm) mu')\n","plt.ylabel('density')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.12"],"metadata":{}},{"source":["std = np.linspace(-10,60, 150)\n","plt.plot(std, stats.uniform.pdf(std, 0, 50))\n","plt.xlabel('heights (cm) std')\n","plt.ylabel('density')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.13"],"metadata":{}},{"source":["samples = int(1e4)\n","sample_mu = np.random.normal(loc = 178, scale = 20, size = samples)\n","sample_sigma = np.random.uniform(low= 0, high = 50, size = samples)\n","prior_h = np.random.normal(loc = sample_mu, scale = sample_sigma, size = samples)\n","sns.distplot(prior_h)\n","plt.xlabel('height (cm)')\n","plt.ylabel('density')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.14"],"metadata":{}},{"source":["mu_list = np.linspace(140,160,num = 200)\n","sigma_list = np.linspace(4,9, num = 200)\n","post = np.array(np.meshgrid(mu_list, sigma_list)).reshape(2, -1).T\n","log_likeli=  [sum(stats.norm.logpdf(x = d2.height ,loc = post[i,0],scale = post[i,1])) for i in range(len(post))]\n","post_prodll = (log_likeli \n","               + stats.norm.logpdf(post[:,0], loc= 178, scale = 20)\n","               + stats.uniform.logpdf(post[:,1], loc = 0 ,scale = 50)\n","              )\n","post_prod = np.exp(post_prodll - max(post_prodll))\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.15"],"metadata":{}},{"source":["#code from pymc3\n","# post = np.mgrid[140:160:0.1, 4:9:0.1].reshape(2,-1).T\n","\n","# likelihood = [sum(stats.norm.logpdf(d2.height, loc=post[:,0][i], scale=post[:,1][i])) for i in range(len(post))]\n","\n","# post_prod = (likelihood + \n","#              stats.norm.logpdf(post[:,0], loc=178, scale=20) + \n","#              stats.uniform.logpdf(post[:,1], loc=0, scale=50))\n","# post_prob = np.exp(post_prod - max(post_prod))"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.15\n"," this one was borrowed from the PYMC3 as I needed help"],"metadata":{}},{"source":["xi = np.linspace(post[:,0].min(), post[:,0].max(), 100)\n","yi = np.linspace(post[:,1].min(), post[:,1].max(), 100)\n","zi = griddata((post[:,0], post[:,1]), post_prod, (xi[None,:], yi[:,None]))\n","\n","plt.contour(xi, yi, zi)\n","plt.xlabel('height')\n","plt.ylabel('height sigma')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.16-.17"],"metadata":{}},{"source":["size = int(1e5)\n","nrows, ncols = post.shape\n","np.random.seed(42)\n","post_sample = np.random.choice(np.arange(nrows),size = size, replace = True, p =( post_prod/post_prod.sum()))\n","sample_mu = post[post_sample,0]\n","sample_sig = post[post_sample,1]\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.18"],"metadata":{}},{"source":["sns.jointplot(sample_mu, sample_sig, kind = 'hex',)\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.19-.20"],"metadata":{}},{"source":["sns.kdeplot(sample_mu)\n","plt.xlabel('sample_mu')\n","plt.ylabel('density')\n","plt.show()\n","sns.kdeplot(sample_sig)\n","plt.xlabel('sample_sigma')\n","plt.ylabel('density')\n","plt.show()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["print(az.hpd(sample_mu, credible_interval=0.5))\n","az.hpd(sample_sig, credible_interval=0.5)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.21"],"metadata":{}},{"source":["d3 = np.random.choice(d2.height, size = 20, replace = False)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.22-.23\n"," We are doing this because we want to show that the posterior is not always\n"," gaussian in shape. This is not driven by the mean it's more driven by the variance which tends to have this right tail"],"metadata":{}},{"source":["mu_list = np.linspace(150,170,num = 200)\n","sigma_list = np.linspace(4,20, num = 200)\n","post = np.array(np.meshgrid(mu_list, sigma_list)).reshape(2, -1).T\n","log_likeli=  [sum(stats.norm.logpdf(x = d3 ,loc = post[i,0],scale = post[i,1])) for i in range(len(post))]\n","post_prodll = (log_likeli \n","               + stats.norm.logpdf(post[:,0], loc= 178, scale = 20)\n","               + stats.uniform.logpdf(post[:,1], loc = 0 ,scale = 50)\n","              )\n","post_prod = np.exp(post_prodll - max(post_prodll))\n","\n","size = int(1e5)\n","nrows, ncols = post.shape\n","np.random.seed(42)\n","post_sample = np.random.choice(np.arange(nrows),size = size, replace = True, p =( post_prod/post_prod.sum()))\n","sample_mu = post[post_sample,0]\n","sample_sig = post[post_sample,1]\n","\n","# look at the tails of the distribution and the which is driven by the std dev\n","sns.distplot(sample_sig)\n","plt.show()\n","sns.jointplot(sample_mu, sample_sig, kind = 'hex',)\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.24"],"metadata":{}},{"source":["d = pd.read_csv('.\\data\\Howell1.csv', sep = \";\")\n","d2 = d.query('age >= 18')\n","\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.25"],"metadata":{}},{"source":["with pm.Model() as m4_1:\n","    mu = pm.Normal('mu', mu=178, sd=20)\n","    sigma = pm.Uniform('sigma', lower=0, upper=50)\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=d2.height)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.26"],"metadata":{}},{"source":["with m4_1:\n","    trace4_1 = pm.sample(1000, tune=1000)\n","pm.traceplot(trace4_1, varnames = ['mu','sigma'])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.27"],"metadata":{}},{"source":["# from the book, \"The means that the plausibility of each value of mu, after averaging over the plausibilities of each value of sigma\n","# , is given by a gaussian distribution with mean of 154.6 and std dev of .4\"\n","pm.summary(trace4_1)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.28"],"metadata":{}},{"source":["# now say we want to inform the prior with the mean of our data\n","with pm.Model() as m4_1:\n","    mu = pm.Normal('mu', mu=178, sd=20, testval=d2.height.mean())\n","    sigma = pm.Uniform('sigma', lower=0, upper=50, testval=d2.height.std())\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=d2.height)\n","    trace4_1 = pm.sample(1000, tune=1000)\n","\n","pm.summary(trace4_1)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Just want to look at the traceplot of this\n","pm.traceplot(trace4_1, varnames = ['mu','sigma'])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.29"],"metadata":{}},{"source":["# now say we want to inform the prior with the mean of our data\n","with pm.Model() as m4_2:\n","    mu = pm.Normal('mu', mu=158, sd=.1)                                 #this is our prior were making it stronger by decreasing sd\n","    sigma = pm.Uniform('sigma', lower=0, upper=50)\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=d2.height)\n","    trace4_2 = pm.sample(1000, tune=1000)\n","\n","pm.summary(trace4_2)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Just want to look at the traceplot of this\n","pm.traceplot(trace4_2, varnames = ['mu','sigma'])\n","plt.show()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.30 - 4.32"],"metadata":{}},{"source":["# What does this tell us?\n","# It tells us how the paramters vary within themselves AND how they are related to each other\n","trace_df = pm.trace_to_dataframe(trace4_1)\n","trace_df.cov()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#this just shows us the variances and how correlated each are to each other\n","np.diag(trace_df.cov())\n","# given the values are so low basically knowing the mean tells us nothing about sigma\n","trace_df.corr()\n","trace_df.head()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.33"],"metadata":{}},{"source":["pm.summary(trace4_1)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.34"],"metadata":{}},{"source":["# In the book this is the underlying extract samples\n","stats.multivariate_normal.rvs(mean= trace_df.mean(), cov = trace_df.cov(), size = 100)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.35 - 4.36"],"metadata":{}},{"source":["with pm.Model() as m4_1_log:\n","    mu = pm.Normal('mu', mu=158, sd=.1)                                 #this is our prior were making it stronger by decreasing sd\n","    sigma = pm.Lognormal('sigma', mu = 2, tau = .01)\n","    height = pm.Normal('height', mu=mu, sd=np.exp(sigma), observed=d2.height)\n","    trace4_1log = pm.sample(1000, tune=1000)\n","\n","pm.summary(trace4_1log)\n","pm.traceplot(trace4_1log)\n","plt.show()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.37"],"metadata":{}},{"source":["plt.plot(d2.height, d2.weight, marker = 'o', linestyle = '')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.38"],"metadata":{}},{"source":["with pm.Model() as m4_3:\n","    a = pm.Normal('a',mu = 156, sigma=100)\n","    b = pm.Normal('b',mu = 0, sigma=10)\n","    mu = a + b * d2.weight\n","    sigma = pm.Uniform('sigma', lower=0, upper=50)\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=d2.height)\n","    trace4_3 = pm.sample(1000, tune=1000)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["pm.summary(trace4_3)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.39"],"metadata":{}},{"source":["with pm.Model() as m4_39:\n","    a = pm.Normal('a',mu = 178, sigma=100)\n","    b = pm.Normal('b',mu = 0, sigma=10)\n","    mu = a + b*d2.weight\n","    sigma = pm.Uniform('sigma', lower=0, upper=50)\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=d2.height)\n","    trace4_39 = pm.sample(1000, tune=1000)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.40"],"metadata":{}},{"source":["pm.summary(trace4_39)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.41"],"metadata":{}},{"cell_type":"markdown","source":[" ### Code 4.43"],"metadata":{}},{"source":["d2['weight_c'] = d2.weight - d2.weight.mean()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.44"],"metadata":{}},{"source":["with pm.Model() as m4_44:\n","    a = pm.Normal('a',mu = 178, sigma=100)\n","    b = pm.Normal('b',mu = 0, sigma=10)\n","    mu = a + b*d2.weight_c\n","    sigma = pm.Uniform('sigma', lower=0, upper=50)\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=d2.height)\n","    tracem4_44 = pm.sample(1000, tune=1000)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.44_cont"],"metadata":{}},{"source":["pm.summary(tracem4_44)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["trace_df_444 = pm.trace_to_dataframe(tracem4_44)\n","trace_df_444.corr()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.45"],"metadata":{}},{"source":["plt.plot(d2.weight_c, d2.height, marker = '.', linestyle = '')\n","plt.plot(d2.weight_c, trace_df_444['a'].mean() + trace_df_444['b'].mean()*d2.weight_c)\n","plt.ylabel('height')\n","plt.xlabel('weight Centered')"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.46"],"metadata":{}},{"source":["trace_df_444\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.47"],"metadata":{}},{"source":["trace_df_444[1:5]\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.48"],"metadata":{}},{"source":["row_sel = 10\n","dn = d2.iloc[range(0,row_sel),:]\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.49"],"metadata":{}},{"source":["with pm.Model() as m4_49:\n","    a = pm.Normal('a',mu = 178, sigma=100)\n","    b = pm.Normal('b',mu = 0, sigma=10)\n","    mu = a + b*dn.weight_c\n","    sigma = pm.Uniform('sigma', lower=0, upper=50)\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=dn.height)\n","    tracem4_49 = pm.sample(1000, tune=1000)\n","# "],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["trace_df_449 = pm.trace_to_dataframe(tracem4_49)\n","trace_df_449"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["for i in range(0,21):\n","    plt.plot(dn.weight_c, dn.height, marker = '.', linestyle = '', color = 'blue', alpha = .2)\n","    plt.plot(dn.weight_c, trace_df_449['a'][i] + trace_df_449['b'][i]*dn.weight_c, color = 'grey', alpha = .2)\n","    plt.ylabel('height', color = 'white')\n","    plt.xlabel('weight Centered')\n","    plt.title('N=10')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.50"],"metadata":{}},{"source":["# we have to use the one that's not centered\n","mu_at_50 = trace4_39['a'] + trace4_39['b']*50\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["sns.distplot(mu_at_50, hist = False)\n","plt.xlabel('mu|weight = 50')\n","plt.ylabel('Density')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.52"],"metadata":{}},{"source":["az.hpd(mu_at_50, credible_interval=0.89)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.53-4.55"],"metadata":{}},{"source":["weight_seq = np.arange(25,76)\n","condensed = trace4_39[::10]\n","mu = np.zeros(shape=(len(condensed['a']),len(weight_seq)))\n","for col, weight in enumerate(weight_seq):\n","    mu[:,col] = condensed['a'] + condensed['b']*weight"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["plt.plot(weight_seq, mu.T, 'C0.', alpha = .2)\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.56"],"metadata":{}},{"source":["# \"THese are just different kinds of summaries of the distributions in mu, with each column being a different weight value\"\n","mu_mean = np.mean(mu,axis = 1)                # average at each weight value\n","mu_hpd = az.hpd(mu, credible_interval=.89)   # 89% highest density estimate for each weight"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# as the book states it's helpful to plot and take a look at things\n","plt.plot(np.mean(mu, axis = 1), marker = '.', linestyle = '', alpha = .2)\n","plt.xlabel('record')\n","plt.ylabel('estimated mu')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.57"],"metadata":{}},{"source":["plt.plot(d2.weight, d2.height, marker = '.', linestyle = '', alpha = .5)\n","plt.plot(d2.weight, trace_df_439['a'].mean() + trace_df_439['b'].mean()*d2.weight)\n","plt.fill_between(weight_seq,mu_hpd[:,0], mu_hpd[:,1], color = 'white', alpha = .2 )\n","plt.xlabel('weight')\n","plt.ylabel('height')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Here's the reciepe for generating predictions and intervals from the posterior\n"," 1. The book uses the link function but we used code 4.53 or loop over the different valeus\n","   - besides pymc3 drew 4000 samples so we are computing that\n"," 2. use summary functions mean and HPDI to find mean, lower and upper\n"," 3. plot the lines and shade the HPDI to see the plausbility\n",""],"metadata":{}},{"cell_type":"markdown","source":[" ### Code 4.58\n"," 1. see 4.53"],"metadata":{}},{"cell_type":"markdown","source":[" ### Code 4.59"],"metadata":{}},{"source":["# We are sampling from the posterior. We are generating 400 samples of the 352 records\n","height_samps = pm.sample_posterior_predictive(trace4_39, samples = 400,model = m4_39)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.60"],"metadata":{}},{"source":["height_hpd = az.hpd(height_samps['height'], credible_interval=.89)\n","height_hpd.shape\n","height_hpd_sort = np.sort(height_hpd, axis=0)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# the jaggedness is the simulation variance in the tails of the distrubtion\n","plt.plot(d2.weight, d2.height, marker = '.', linestyle = '', alpha = .5)\n","plt.plot(d2.weight, trace_df_439['a'].mean() + trace_df_439['b'].mean()*d2.weight, color = 'white')\n","plt.fill_between(weight_seq,mu_hpd[:,0], mu_hpd[:,1], color = 'white', alpha = .5 )\n","plt.fill_between(d2.weight.sort_values(),height_hpd_sort[:,0],height_hpd_sort[:,1], color = 'white', alpha = .2 )\n","plt.xlabel('weight')\n","plt.ylabel('height')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.63\n"," It's useful to know how to manuall sample. THe below was taken from the pymc3 devs"],"metadata":{}},{"source":["weigth_seq = np.arange(25, 71)\n","post_samples = []\n","for _ in range(1000): # number of samples from the posterior\n","    i = np.random.randint(len(trace4_39))\n","    mu_pred = trace4_39['a'][i] + trace4_39['b'][i] * weigth_seq\n","    sigma_pred = trace4_39['sigma'][i]\n","    post_samples.append(np.random.normal(mu_pred, sigma_pred))\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.64"],"metadata":{}},{"source":["d = pd.read_csv('.\\data\\Howell1.csv', sep = \";\")\n","d.head()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.65"],"metadata":{}},{"source":["plt.plot('weight','height', data = d, marker = '.', linestyle = '')\n","plt.show()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.65"],"metadata":{}},{"source":["d['weight_sd'] = (d.weight - d.weight.mean())/d.weight.std()\n","d['weight_sd2'] = d.weight_sd**2\n","plt.plot('weight_sd','height', data = d, marker = '.', linestyle = '')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.66"],"metadata":{}},{"source":["with pm.Model() as m4_66:\n","    a = pm.Normal('alpha',mu = 178, sigma=100)\n","    b1 = pm.Normal('beta1',mu = 0, sigma=10)\n","    b2 = pm.Normal('beta2',mu = 0, sigma=10)\n","    sigma = pm.Uniform('sigma', lower=0, upper=50)\n","    mu =  pm.Deterministic('mu', a + b1*d.weight_sd + b2*d.weight_sd2)\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=d.height)\n","    trace466 = pm.sample(1000, tune=1000)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.67"],"metadata":{}},{"source":["pm.summary(trace466, var_names = ['alpha', 'beta1','beta2','sigma'])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.68"],"metadata":{}},{"source":["idx = np.argsort(d.weight_sd)\n","height_samps = pm.sample_posterior_predictive(trace466, samples = 1000,model = m4_66)\n","mu_pred = trace466['mu']\n","mu_hpd = az.hpd(mu_pred, credible_interval=.89)[idx]\n","height_hpd = az.hpd(height_samps['height'], credible_interval=.89)\n","height_hpd_sort = np.sort(height_hpd, axis=0)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.69"],"metadata":{}},{"source":["# the jaggedness is the simulation variance in the tails of the distrubtion\n","plt.plot(d.weight_sd, d.height, marker = '.', linestyle = '', alpha = .5)\n","plt.fill_between(d.weight_sd[idx], mu_hpd[:,0], mu_hpd[:,1], color='C2', alpha=0.7)\n","plt.fill_between(d.weight_sd[idx],height_hpd_sort[:,0],height_hpd_sort[:,1], color = 'white', alpha = .2 )\n","plt.xlabel('weight')\n","plt.ylabel('height')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Code 4.70"],"metadata":{}},{"source":["d['weight_sd3'] = d.weight_sdd**3\n","\n","with pm.Model() as m4_70:\n","    a = pm.Normal('alpha',mu = 178, sigma=100)\n","    b1 = pm.Normal('beta1',mu = 0, sigma=10)\n","    b2 = pm.Normal('beta2',mu = 0, sigma=10)\n","    b3 = pm.Normal('beta3',mu = 0, sigma=10)\n","    sigma = pm.Uniform('sigma', lower=0, upper=50)\n","    mu =  pm.Deterministic('mu', a + b1*d.weight_sd + b2*d.weight_sd2 + b3*d.weight_sd3)\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=d.height)\n","    trace470 = pm.sample(1000, tune=1000)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["pm.summary(trace470, var_names = ['alpha', 'beta1','beta2','beta3','sigma'])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["idx = np.argsort(d.weight_sd)\n","height_samps = pm.sample_posterior_predictive(trace470, samples = 1000,model = m4_70)\n","mu_pred = trace470['mu']\n","mu_hpd = az.hpd(mu_pred, credible_interval=.89)[idx]\n","height_hpd = az.hpd(height_samps['height'], credible_interval=.89)\n","height_hpd_sort = np.sort(height_hpd, axis=0)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# the jaggedness is the simulation variance in the tails of the distrubtion\n","plt.plot(d.weight_sd, d.height, marker = '.', linestyle = '', alpha = .5)\n","plt.fill_between(d.weight_sd[idx], mu_hpd[:,0], mu_hpd[:,1], color='C2', alpha=0.7)\n","plt.fill_between(d.weight_sd[idx],height_hpd_sort[:,0],height_hpd_sort[:,1], color = 'white', alpha = .2 )\n","plt.xlabel('weight')\n","plt.ylabel('height')\n","plt.show()\n","\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # Practice Questions\n"," ## Medium\n"," ### 4M1"],"metadata":{}},{"source":["# simulating observations for the prior\n","nums = int(1e4)\n","mu = np.random.normal(0,10,size = nums)\n","sigma = np.random.uniform(0,10,size = nums)\n","y_sim = np.random.normal(mu, sigma , size = nums)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### 4M2"],"metadata":{}},{"source":["with pm.Model() as m4M1:\n","    mu = pm.Normal('mu', mu=0, sd=10)\n","    sigma = pm.Uniform('sigma', lower=0, upper=10)\n","    y = pm.Normal('y', mu=mu, sd=sigma, observed = y_sim)\n","    trace4M1 = pm.sample(1000, tune=1000)\n","\n","pm.traceplot(trace4M1, varnames = ['mu','sigma'])\n","pm.summary(trace4M1)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # Practice Questions\n"," ## Hard\n"," ### 4H1"],"metadata":{}},{"source":["d = pd.read_csv('.\\data\\Howell1.csv', sep = \";\")\n","d['weight_sd'] = (d.weight - d.weight.mean())/d.weight.std()\n","d.head()\n","\n","shared_x = tt.shared(d.weight_sd.values)\n","shared_y = tt.shared(d.height.values)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["with pm.Model() as m4h1:\n","    a = pm.Normal('alpha',mu = 178, sigma=100)\n","    b = pm.Normal('beta',mu = 0, sigma=10)\n","    mu = a + b*shared_x\n","    sigma = pm.Uniform('sigma', lower=0, upper=50)\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=shared_y)\n","    tracem4H1 = pm.sample(1000, tune=1000)\n","\n","pm.traceplot(tracem4H1, varnames = ['mu','sigma', 'beta','alpha'])\n","pm.summary(tracem4H1)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# predicting out of sample via PYMC3\n","# pymc3 or better yet theano assumes that when you pass data into a model you are giving Theano \n","# permission to keep the data constant and optimize as it sees fit\n","# https://docs.pymc.io/notebooks/api_quickstart.html#4.1-Predicting-on-hold-out-data\n","ind_weights = np.array([46.95,43.72,64.78,32.59,54.63])\n","ind_weight_cent = (ind_weights - d.weight.mean())/d.weight.std()\n","shared_x.set_value(ind_weight_cent)\n","shared_y.set_value(np.repeat(0, repeats = len(ind_weight_cent)))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["with m4h1:\n","    post_pred = pm.sample_posterior_predictive(tracem4H1,samples = 400,model=m4h1)\n","height_hpd = az.hpd(post_pred['height'], credible_interval= 0.89)\n","post_pred['height'].mean(axis = 0)\n","del post_pred \n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## Hard\n"," ### 4H2"],"metadata":{}},{"source":["d_lt18 = d.query('age < 18')\n","d_lt18.weight.values"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["shared_x = tt.shared(d_lt18.weight.values)\n","shared_y = tt.shared(d_lt18.height.values)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["with pm.Model() as m4h2:\n","    a = pm.Normal('alpha',mu = 50, sigma=100)\n","    b = pm.Normal('beta',mu = 0, sigma=10)\n","    mu = pm.Deterministic('mu',a + b*shared_x)\n","    sigma = pm.Uniform('sigma', lower=0, upper=50)\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=shared_y)\n","    tracem4H2 = pm.sample(1000, tune=1000)\n","\n","pm.traceplot(tracem4H2, varnames = ['sigma', 'beta','alpha'])\n","pm.summary(tracem4H2,varnames = ['sigma', 'beta','alpha'])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#4H2a - A child gets roughly 27\n","print(f'for every 10 units of increase in weight an individual will be {tracem4H2[\"beta\"].mean()*10} taller')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#4H2b\n","pred_height_samps = pm.sample_posterior_predictive(tracem4H2, samples = 2000, model = m4h2)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["mu_pred = tracem4H2['mu']\n","mu_pred_sort = np.sort(\n","    az.hpd(mu_pred, credible_interval = .89), axis = 0)\n","height_hpd_sort = np.sort(\n","    az.hpd(pred_height_samps['height'], credible_interval = .89), axis = 0)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["plt.figure(figsize = (10,10))\n","plt.plot(d_lt18.weight, d_lt18.height, marker = '.', linestyle = '', alpha = .5, color = 'orange')\n","plt.plot(d_lt18.weight, tracem4H2['alpha'].mean() + tracem4H2['beta'].mean()*d_lt18.weight, color = 'white')\n","plt.fill_between(np.sort(d_lt18.weight), mu_pred_sort[:,0], mu_pred_sort[:,1], color='white', alpha=0.7)\n","plt.fill_between(np.sort(d_lt18.weight),height_hpd_sort[:,0], height_hpd_sort[:,1], color = 'grey' )\n","plt.ylabel('height')\n","plt.xlabel('weight')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ##4H2c\n"," The aspects of this that concern me are we are assuming the relationship is linear when it appears to be non-linear\n"," Adding in a non-linear term to the model would help improve the model"],"metadata":{}},{"cell_type":"markdown","source":[" ## Hard\n"," ### 4H3"],"metadata":{}},{"source":["shared_x = tt.shared(d.weight.values)\n","shared_y = tt.shared(d.height.values)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["with pm.Model() as m4h3:\n","    a = pm.Normal('alpha',mu = 50, sigma=100)\n","    b = pm.Normal('beta',mu = 0, sigma=10)\n","    mu = pm.Deterministic('mu',a + b*np.log(shared_x))\n","    sigma = pm.Uniform('sigma', lower=0, upper=50)\n","    height = pm.Normal('height', mu=mu, sd=sigma, observed=shared_y)\n","    tracem4H3 = pm.sample(1000, tune=1000)\n","\n","pm.traceplot(tracem4H3, varnames = ['sigma', 'beta','alpha'])\n","pm.summary(tracem4H3,varnames = ['sigma', 'beta','alpha'])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["mu_pred = tracem4H3['mu']\n","mu_pred_sort = np.sort(\n","    az.hpd(mu_pred, credible_interval = .97), axis = 0)\n","\n","pred_height_samps = pm.sample_posterior_predictive(tracem4H3, samples = 2000, model = m4h3)\n","height_hpd_sort = np.sort(\n","    az.hpd(pred_height_samps['height'], credible_interval = .97), axis = 0)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["plt.figure(figsize=(10,8))\n","plt.plot(d.weight, d.height, color = 'orange', marker = '.', linestyle = '')\n","plt.plot(d.weight.sort_values(), tracem4H3['alpha'].mean() + tracem4H3['beta'].mean()*np.log(d.weight.sort_values()), color = 'white', alpha = 1)\n","plt.fill_between(np.sort(d.weight), mu_pred_sort[:,0], mu_pred_sort[:,1], color='white', alpha=0.3)\n","plt.fill_between(np.sort(d.weight),height_hpd_sort[:,0], height_hpd_sort[:,1], color = 'grey' )\n","plt.xlabel('weight')\n","plt.ylabel('height')\n","plt.title('Howell Data with log transformed weight', fontsize = 18)\n","plt.show()\n","\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":[""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}